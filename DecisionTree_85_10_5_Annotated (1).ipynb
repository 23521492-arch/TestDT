{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3f0f75",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Required libraries\n",
    "\n",
    "We import libraries for data handling, training, evaluation, and saving artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713671b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cefad1f",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Load dataset\n",
    "\n",
    "Notes:\n",
    "- `parse_dates=['date']` converts to `datetime64`, needed for time-based processing and split.  \n",
    "- Sorting by the datetime index preserves temporal order for lag features and splitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54854fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'household.csv'\n",
    "df = pd.read_csv(path, parse_dates=['date'], low_memory=True)\n",
    "df = df.set_index('date').sort_index()\n",
    "\n",
    "\n",
    "df = df.drop(columns=['main','description'], errors='ignore')\n",
    "\n",
    "print(\"Dataset shape (rows, cols):\", df.shape)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa296b5c",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Quick EDA\n",
    "\n",
    "Goal: list useful columns and check missing values for the data description section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667a51ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isna().sum())\n",
    "display(df.describe().T[['count','mean','std','min','max']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2db3b3c",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Feature engineering — key features\n",
    "\n",
    "Explanation of created features:\n",
    "- `ap_lag_1h`: `active_power` one hour ago — short-term autocorrelation.  \n",
    "- `ap_lag_24h`: same hour of the previous day — daily cycle.  \n",
    "- `ap_roll_24h`: 24-hour rolling mean — trend.  \n",
    "- `hour, weekday, is_weekend`: time-of-day, day-of-week, and weekend indicator.\n",
    "\n",
    "Technical note: create features on a copy (`data = df.copy()`) to avoid growing `df` when re-running cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dbecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = df.copy()\n",
    "\n",
    "# Lag features\n",
    "data['ap_lag_1h'] = data['active_power'].shift(1)\n",
    "data['ap_lag_24h'] = data['active_power'].shift(24)\n",
    "\n",
    "# 24h rolling mean (drop NA later)\n",
    "data['ap_roll_24h'] = data['active_power'].rolling(window=24, min_periods=1).mean()\n",
    "\n",
    "# Time features\n",
    "data['hour'] = data.index.hour\n",
    "data['weekday'] = data.index.weekday\n",
    "data['is_weekend'] = (data['weekday'] >= 5).astype(int)\n",
    "\n",
    "\n",
    "keep = ['active_power','ap_lag_1h','ap_lag_24h','ap_roll_24h',\n",
    "        'temp','feels_like','humidity','pressure','speed',\n",
    "        'current','voltage','apparent_power','hour','weekday','is_weekend']\n",
    "keep = [c for c in keep if c in data.columns]\n",
    "\n",
    "# Drop NA caused by lag/rolling\n",
    "data = data[keep].dropna().copy()\n",
    "\n",
    "print(\"After feature engineering shape (rows, cols):\", data.shape)\n",
    "display(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8b5bd9",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Split dataset — 85% Train / 10% Validate / 5% Test (time-based)\n",
    "\n",
    "Explanation:\n",
    "- **Train (85%)**: learn patterns on a large portion to stabilize time-series training.  \n",
    "- **Validate (10%)**: select hyperparameters and check generalization before the final test.  \n",
    "- **Test (5%)**: held-out data for the final report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c0de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n = len(data)\n",
    "train_end = int(n * 0.85)\n",
    "val_end = int(n * 0.95)\n",
    "\n",
    "train = data.iloc[:train_end].copy()\n",
    "validate = data.iloc[train_end:val_end].copy()\n",
    "test = data.iloc[val_end:].copy()\n",
    "\n",
    "print(\"Split sizes -> train, validate, test:\", train.shape, validate.shape, test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4916cfd4",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Prepare X and y for each split\n",
    "\n",
    "We separate features and target for train/validate/test to use validation independently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9453fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TARGET = 'active_power'\n",
    "\n",
    "X_train = train.drop(columns=[TARGET])\n",
    "y_train = train[TARGET]\n",
    "\n",
    "X_val = validate.drop(columns=[TARGET])\n",
    "y_val = validate[TARGET]\n",
    "\n",
    "X_test = test.drop(columns=[TARGET])\n",
    "y_test = test[TARGET]\n",
    "\n",
    "print(\"Feature count:\", X_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2398d6",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Scaling (why)\n",
    "\n",
    "Decision Trees do not require scaling, but we standardize inputs to keep consistency across models and ensure stable GridSearch behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113aef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scale: fit on train, transform on val/test\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s = scaler.transform(X_val)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "print(\"Scaling completed. (scaler mean sample of first feature)\", scaler.mean_[0] if hasattr(scaler,'mean_') else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a54cea4",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Hyperparameter tuning on TRAIN with TimeSeriesSplit\n",
    "\n",
    "We tune `max_depth` and `min_samples_leaf` to control overfitting. We use `TimeSeriesSplit` (no shuffle). Cross-validation runs only on TRAIN to avoid leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GridSearch with TimeSeriesSplit (train only)\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "param_grid = {'max_depth': [5, 8, 12, None], 'min_samples_leaf': [1, 2, 4]}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "gscv = GridSearchCV(model, param_grid, scoring='neg_mean_absolute_error', cv=tscv, n_jobs=-1, verbose=1)\n",
    "\n",
    "gscv.fit(X_train_s, y_train)\n",
    "\n",
    "print(\"Best params from CV on train:\", gscv.best_params_)\n",
    "print(\"Best CV (neg MAE):\", gscv.best_score_)\n",
    "best = gscv.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d3d578",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Evaluate on VALIDATE\n",
    "\n",
    "Use the validation set to check whether hyperparameters chosen on TRAIN generalize. If metrics are poor, adjust features or grid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbfd408",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_val_pred = best.predict(X_val_s)\n",
    "\n",
    "mae_val = mean_absolute_error(y_val, y_val_pred)\n",
    "rmse_val = mean_squared_error(y_val, y_val_pred, squared=False)\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validate MAE: {mae_val:.4f}, RMSE: {rmse_val:.4f}, R2: {r2_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4a5784",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Refit final model on Train+Validate and evaluate on TEST\n",
    "\n",
    "After validation is satisfactory, refit on TRAIN+VALIDATE to leverage all training data, then evaluate on TEST. Refit the scaler on TRAIN+VALIDATE before transforming TEST.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4934fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Refit scaler and final model on train+validate\n",
    "X_trainval = pd.concat([X_train, X_val], axis=0)\n",
    "y_trainval = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_trainval_s = scaler.fit_transform(X_trainval)\n",
    "X_test_s = scaler.transform(X_test)  # transform test with scaler fitted on train+val\n",
    "\n",
    "final_model = DecisionTreeRegressor(**gscv.best_params_, random_state=42)\n",
    "final_model.fit(X_trainval_s, y_trainval)\n",
    "\n",
    "\n",
    "y_test_pred = final_model.predict(X_test_s)\n",
    "\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test MAE: {mae_test:.4f}, RMSE: {rmse_test:.4f}, R2: {r2_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b574430",
   "metadata": {},
   "source": [
    "\n",
    "## 11) Feature importance — why\n",
    "\n",
    "Feature importance explains which variables the model relies on most (e.g., `ap_lag_1h` vs `ap_roll_24h`). Include the top-15 table in the report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be23cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feat_imp = pd.Series(final_model.feature_importances_, index=X_trainval.columns).sort_values(ascending=False)\n",
    "display(feat_imp.head(15))\n",
    "\n",
    "feat_imp.to_csv('/mnt/data/dt_85_10_5_feature_importance.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af778a5",
   "metadata": {},
   "source": [
    "\n",
    "## 12) Plot Actual vs Predicted (sample) — why a sample\n",
    "\n",
    "Plotting the full test set can be cluttered; we show the first 300 samples to illustrate prediction quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83262e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "n_plot = 300\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(y_test.values[:n_plot], label='Actual')\n",
    "plt.plot(y_test_pred[:n_plot], label='Predicted', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title('Actual vs Predicted (first {} samples of test)'.format(n_plot))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573c831d",
   "metadata": {},
   "source": [
    "\n",
    "## 13) Visualize a small subtree (max_depth=3) — interpretability\n",
    "\n",
    "The full tree can be deep; we plot the first 3 levels for readability. Include this figure in the report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54cf013",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "plot_tree(final_model, feature_names=X_trainval.columns, max_depth=3, filled=True, fontsize=8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce36b449",
   "metadata": {},
   "source": [
    "\n",
    "## 14) Save artifacts (model, metrics, feature importance)\n",
    "\n",
    "Saving artifacts enables reproducibility and reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089f83e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save model and outputs\n",
    "joblib.dump({'model': final_model, 'scaler': scaler, 'features': X_trainval.columns.tolist()},\n",
    "            '/mnt/data/dt_85_10_5_final.joblib')\n",
    "\n",
    "pd.DataFrame({'metric': ['MAE_val','RMSE_val','R2_val','MAE_test','RMSE_test','R2_test'],\n",
    "              'value': [mae_val, rmse_val, r2_val, mae_test, rmse_test, r2_test]}).to_csv('/mnt/data/dt_85_10_5_metrics.csv', index=False)\n",
    "\n",
    "print(\"Saved artifacts to /mnt/data/\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
